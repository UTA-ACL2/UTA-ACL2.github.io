<!DOCTYPE html>
<head>
    
    <!-- Standard Meta -->
    <meta content='text/html; charset=UTF-8' http-equiv='Content-Type'>
    <meta content='IE=edge,chrome=1' http-equiv='X-UA-Compatible'>
    <meta content='width=device-width, initial-scale=1.0, maximum-scale=1.0' name='viewport'>
    <script src="../static/js/application-393d5b43700222f200dcf15f4c0e5b14.js"></script>
    <link rel="stylesheet" media="all" href="../../static/css/reu.css" />
    <link rel="stylesheet" media="all" href="../../static/css/application-ae3e0748f68a2f05d3f535bdeb9fa996.css" />
    <script src="../static/js/reu-0bc27e2168727cafa1252f703137df60.js"></script>
    <title>
        ACLGroup - REU
    </title>
    <script>
        (function() {
          $(function() {
            return $('.ui.sidebar').sidebar({
              context: $('.ui.pushable.segment'),
              transition: 'overlay'
            }).sidebar('attach events', '#mobile_item');
          });
        
        }).call(this);
    </script>
</head>
<body>
    <noscript>
        <iframe height='0' src='https://www.googletagmanager.com/ns.html?id=GTM-5TSVHFZ' style='display:none;visibility:hidden' width='0'></iframe>
    </noscript>
    <style>
        #navbar {
          background: #c31f48;
          border-color: #952e46; }
        
        .logo {
          margin: 0px 0; }
        .logo img {
          height: 40px; }
    </style>

<div class="ui pushable segment">
    
    <div class='ui pusher' id='site-content'>
        <div class='ui container'>
        </div>
        <div class='ui container' id='main'>
        <p style="text-align: center;">
        <img style="width: 1000px;overflow: hidden;" src="../../static/images/aclgroup.png"/>
        </p>
        <h1>
        <div class='subtitle'>Research Experience for Undergraduates Site</div>
        Arlington Computational Linguistics Group (ACLGroup-REU)
        <div class='meta'>The University of Texas at Arlington</div>
        </h1>
        <div class='ui menu stackable'>
        <a class='item' href='../index.html'>REU Site Info</a>
        <a class='item' href='../project_info.html'>Project Info</a>
        <a class='item' href='../faulty_mentors.html'>Faculty Mentors</a>
        <a class='item' href='../graduate_mentors.html'>Graduate Mentors</a>
        <a class='active item' href='index.html'>Projects</a>
        <a class='item' href='../faq.html'>FAQ</a>
        <!-- <a class='item' href='/spaces'>Spaces</a> -->
        <div class='right menu'>
        <div class='item'>
        <a class='ui primary button' href='https://etap.nsf.gov/award/5977/opportunity/7860' target="_blank">Apply</a>
        </div>
        </div>
        </div>

        <div class='ui items divided'>
            <div class='item'>
            <a class="image" href="../../building.html"><img alt="AI-Assisted Glassworking Tools and Connected Wearables" src="../../static/images/code-pic1.jpeg" />
            </a><div class='content'>
            <a class='header' href='../../building.html'>
            AI-oriented Animal Video Clips
            </a>
            <div class='meta'>
            <span>Computer Science Skill</span>
            </div>
            <!-- <div class='meta'>
            <a class="button.small" href="/members/145-justin-e-ginsberg">Justin E Ginsberg</a>
            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>
            <a class="button.small" href="/members/149-amanda-shayna-ahteck">Amanda Shayna Ahteck</a>
            <a class="button.small" href="/members/140-enelin-medrano">Enelin Medrano</a>
            <a class="button.small" href="/members/168-paul-park">Paul Park</a>
            <a class="button.small" href="/members/174-jacob-yank">Jacob Yank</a>
            </div> -->
            <!-- .description= project.description -->
            <div class='description'><p>Abstracting valuable dog bark clips from a YouTube video using AI methods presents challenges such as obtaining a diverse and well-labeled dataset, dealing with background noise and interference, accounting for variability in barking patterns, handling class imbalance, ensuring generalization to unknown scenarios, and minimizing false positives and false negatives. Overcoming these difficulties requires careful dataset curation, robust preprocessing techniques, fine-tuning of the model, and iterative evaluation and refinement to enhance accuracy and reliability of the abstraction process...</p>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            
            <div class='item'>
            <a class="image" href="../../building.html"><img alt="Assistive Light Projection" src="../../static/images/pro1.png" />
            </a><div class='content'>
            <a class='header' href='../../building.html'>
            Data cleaning and segmentation
            </a>
            <div class='meta'>
            <span>Computer Science Skill</span>
<!--            </div>-->
<!--            <div class='meta'>-->
<!--            <a class="button.small" href="/members/146-carlos-daniel-donjuan">Carlos Daniel Donjuan</a>-->
<!--            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>-->
<!--            <a class="button.small" href="/members/151-bijisa-pyakurel">Bijisa Pyakurel</a>-->
<!--            </div>-->
            
            <div class='description'><p>Data cleaning involves using signal processing methods with meticulous quality control to ensure accuracy, while segmentation divides recordings with such techniques into independent, meaningful units (Figure 3). Similar to humans, it is possible to define sentences and words in the sound system of animal expressions. A long audio sample can be divided into several sentences with long pauses in between; a sentence can be further divided into several words with short pauses in between like in the picture below. </p>
            
<!--            <p>Current structured light projectors (e.g., LightForm) provide Photoshop-like design software for adding dynamic textures onto specific surfaces on a scene; however, the ability to prototype LPUIs remains limited....</p>-->
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
                </div>

            
            <div class='item'>
            <a class="image" href="../../building.html"><img alt="Biomaterial Fabrication" src="../../static/images/pro2.png" />
            </a><div class='content'>
            <a class='header' href='../../building.html'>
            Video understanding and scene extraction
            </a>
            <div class='meta'>
            <span>Computer Science Skill</span>
            </div>
<!--            <div class='meta'>-->
<!--            <a class="button.small" href="/members/142-christopher-mcmurrough">Christopher McMurrough</a>-->
<!--            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>-->
<!--            <a class="button.small" href="/members/153-charlotte-anne-jones">Charlotte Anne Jones</a>-->
<!--            <a class="button.small" href="/members/173-mason-willman">Mason Willman</a>-->
<!--            <a class="button.small" href="/members/170-john-puthiaparambil">John Puthiaparambil</a>-->
<!--            </div>-->
            
            <div class='description'><p>Video understanding and scene extraction focus mainly on the visual models for further analysis of the video data gained through the projects. There is a wide range of vocalizations dogs can produce, which are affected by various engaged objects, the emotion of the dog, the surrounding environment the dog is located in, the activity the dog is doing, the object the dog interacts with, and even the age and gender of the dog may play a key factor. </p>
            
<!--            <p>The project goals include: </p>-->
<!--            -->
<!--            <ul>-->
<!--            <li>Streamlining the DIY fabrication workflow for growing SCOBY leather and developing closed-feedback sensing and control of humidity, sugar levels, and temperature for the biomaterial solution; </li>-->
<!--            <li>Refining the SCOBY desiccation process, documenting the different behaviors of solution parameters, and characterizing the...</li>-->
<!--            </ul>-->
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            <!--


            <div class='item'>
            <a class="image" href="/projects/68-clay-3d-printing"><img alt="Clay 3D Printing" src="https://res.cloudinary.com/cearto/image/upload/c_fill,g_center,h_162,w_288/v1645734658/clay.png_ha.png" />
            </a><div class='content'>
            <a class='header' href='/projects/68-clay-3d-printing'>
            Clay 3D Printing
            </a>
            <div class='meta'>
            <span>Hybrid Workflows Track</span>
            </div>
            <div class='meta'>
            <a class="button.small" href="/members/143-yana-a-payusova">Yana A Payusova</a>
            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>
            <a class="button.small" href="/members/148-melody-nigam">Melody Nigam</a>
            <a class="button.small" href="/members/157-matthew-ezra-baeza">Matthew Ezra Baeza</a>
            <a class="button.small" href="/members/171-ciara-sorrells">Ciara Sorrells</a>
            </div>
            
            <div class='description'><p>Clay 3D printing uses a continuous deposition technique to extrude and fuse clay coils into clay forms which can be generalized to other paste-based materials including concrete, food, and silicone printing; however, this technique is limited in the geometries it can support (to prevent rupture during the ceramic firing process). Interactive CAM algorithms could allow a user to recover, repair, and reuse elements of a clay form and yield a more robust, sustainable, and expressive clay printing workflow.</p>
            
            <p>Leveraging established techniques from the ceramics community, this multi-researcher project will use computational and electromechanical methods to develop interactive clay 3D printing techniques.</p>
            
            <p>Project goals would examine modular G-Code decomposition, specifically:</p>
            
            <p>*...</p>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            
            <div class='item'>
            <a class="image" href="/projects/67-computer-aided-translation"><img alt="Computer-aided Translation" src="https://res.cloudinary.com/cearto/image/upload/c_fill,g_center,h_162,w_288/v1646152676/Image_5_copy.jpg_ha.png" />
            </a><div class='content'>
            <a class='header' href='/projects/67-computer-aided-translation'>
            Computer-aided Translation
            </a>
            <div class='meta'>
            <span>Hybrid Workflows Track</span>
            </div>
            <div class='meta'>
            <a class="button.small" href="/members/129-ben-dolezal">Ben Dolezal</a>
            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>
            <a class="button.small" href="/members/155-cristian-munoz">Cristian Munoz</a>
            <a class="button.small" href="/members/167-xiamari-osorio">Xiamari Osorio</a>
            </div>
            
            <div class='description'><p>When designing for physical objects, virtual representations and their physical counterparts rarely match. These common translational errors are often associated with limitations of the machine (e.g., tooling, CNC envelopes, kerf, tolerance) that a machinist would correct in traditional manufacturing. Researchers have explored translating physical measurement to virtual dimensions and vice versa, adjusting for tolerance and kerf in geometries to ensure snug fits, and better understanding where uncertainty in measurement occurs. </p>
            
            <p>In the domain of packaging design, the cognitive load of translating physical measurements onto folding 3D forms remains a significant challenge for novice designers. This project&#39;s goals include: </p>
            
            <ul>
            <li>Understanding the challenges of formmaking within a...</li>
            </ul>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            
            <div class='item'>
            <a class="image" href="/projects/64-conductive-soft-and-metamaterials"><img alt="Conductive Soft and Metamaterials" src="https://res.cloudinary.com/cearto/image/upload/c_fill,g_center,h_162,w_288/v1645727865/Group_101.png_ha.png" />
            </a><div class='content'>
            <a class='header' href='/projects/64-conductive-soft-and-metamaterials'>
            Conductive Soft and Metamaterials
            </a>
            <div class='meta'>
            <span>Smart Material Toolkits Track</span>
            </div>
            <div class='meta'>
            <a class="button.small" href="/members/147-ashfaq-adnan">Ashfaq Adnan</a>
            <a class="button.small" href="/members/144-vp-nguyen-">VP Nguyen </a>
            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>
            <a class="button.small" href="/members/118-shreyosi-endow">Shreyosi Endow</a>
            <a class="button.small" href="/members/150-yukti-dhirenkumar-shinglot">Yukti Dhirenkumar Shinglot</a>
            <a class="button.small" href="/members/169-vi-pham">Vi Pham</a>
            <a class="button.small" href="/members/172-amanda-westmoreland">Amanda Westmoreland</a>
            </div>
            
            <div class='description'><p>Embedding electronics within silicone rubber and other soft materials show large promise for creating interactive, soft, flexible, and wearable artifacts. Recent DIY techniques have demonstrated accessible and low-cost methods of creating conductive silicone using graphite powder or chopped carbon fiber. In HCI, conductive silicone has been used to improve rapid electronics prototyping techniques for on-body wearable electronics prototyping. This project aims to develop a framework for understanding the design capabilities of conductive silicone, conductive polymers and their nanocomposites, or electrically conductive gelatin hydrogels. This framework will be used to develop methods of integrating soft conductive materials within interactive artifacts. </p>
            
            <p>The project goals include: </p>
            
            <p>...</p>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            
            <div class='item'>
            <a class="image" href="/projects/77-material-ecologies-and-literacy">
            </a><div class='content'>
            <a class='header' href='/projects/77-material-ecologies-and-literacy'>
            Material Ecologies and Literacy
            </a>
            <div class='meta'>
            <span></span>
            </div>
            <div class='meta'>
            <a class="button.small" href="/members/1-cesar-torres">Cesar Torres</a>
            <a class="button.small" href="/members/175-adam-emerson">Adam Emerson</a>
            <a class="button.small" href="/members/166-marisa-fernandez">Marisa Fernandez</a>
            </div>
            
            <div class='description'><p>The vision that digital fabrication will one day reach the scale and popularity of desktop computing has significant implications for broadening participation in engineering and computing. As the types of materials supported by digital fabrication continue to grow, so does the need to support the development of material literacy, or a fluency in working creatively with different materials. Personal fabrication has the potential to integrate the knowledge that material practitioners have developed over centuries, yet accessing such material knowledge remains a difficult pursuit --- the canonical step-by-step tutorial struggles to communicate the information needed for users to extract generalizable and creative insights that go beyond rote step-by-step instructions.</p>
            
            <p>Through this...</p>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div>
            
            <div class='item'>
            <a class="image" href="/projects/66-sensor-input-toolkits"><img alt="Sensor Input Toolkits" src="https://res.cloudinary.com/cearto/image/upload/c_fill,g_center,h_162,w_288/v1645740662/teaser__5_.png_ha.png" />
            </a><div class='content'>
            <a class='header' href='/projects/66-sensor-input-toolkits'>
            Sensor Input Toolkits
            </a>
            <div class='meta'>
            <span>Smart Material Toolkits Track</span>
            </div>
            <div class='meta'>
            <a class="button.small" href="/members/144-vp-nguyen-">VP Nguyen </a>
            <a class="button.small" href="/members/142-christopher-mcmurrough">Christopher McMurrough</a>
            <a class="button.small" href="/members/154-tina-ko">Tina Ko</a>
            <a class="button.small" href="/members/170-john-puthiaparambil">John Puthiaparambil</a>
            </div>
            
            <div class='description'><p>The work builds on research in HCI aiming to retrofit existing tools with sensor capabilities.The project goals include:</p>
            
            <ul>
            <li>Developing a set of signal processing primitives and assess their composability to different sensing approaches (e.g., resistive, inductive, passive)</li>
            <li>Retrofitting a suite of tools with physiological, environmental, and inertial sensors while developing their gesture recognition capabilities. </li>
            </ul>
            
            <p>REU participants should expect to work collaboratively with out REU projects to apply and test sensor-retrofitted tools. For instance, tools can be used to:</p>
            
            <ul>
            <li>sense biomaterial sugar levels in the Biomaterial Fabrication project.</li>
            <li>extracting position-based or gesture-based data from the Conductive Soft Materials project.</li>
            </ul>
            
            <p>This work will result in research...</p>
            </div>
            <div class='extra'>
            <div class='ui label'>
            
            2023
            </div>
            </div>
            </div>
            </div> -->
        
        </div>

        </div>
        <div class='ui vertical footer segment'>
        <div class='ui center aligned container'>
        <p>
        <a href='/'>
        <strong>ACL<sup>2</sup> </strong>
        </a>
        © The University of Texas at Arlington
        2023-2023
        <br>
        <em>
        Last updated
        2023-09-25 12:32:23 UTC
        </em>
        </p>
        </div>
        </div>
        </div>
</div>
    
</body>
